{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 title price rating  \\\n",
      "0    Amazon Essentials Henley Long Sleeve Shirts fo...   19.    4.6   \n",
      "1    J.VER Men's Dress Shirts Solid Long Sleeve Str...   23.    4.4   \n",
      "2    J.VER Men's Dress Shirts Stretch Stain Shield ...  None    4.5   \n",
      "3    Men's Stretch Wrinkle Free Dress Shirts Formal...  None    4.4   \n",
      "4    Van Heusen Men's Dress Shirt Regular Fit Popli...   38.    4.4   \n",
      "..                                                 ...   ...    ...   \n",
      "235  Ylingjun Mens Baggy Hip Hop Jeans Casual Loose...   63.    4.3   \n",
      "236  Baggy Cargo Pants for Men Women Wide Leg Jeans...   44.    4.0   \n",
      "237  Men's Baggy Vintage Jeans Loose Fit Denim Pant...   40.    4.4   \n",
      "238  Men Grunge Jeans Vintage Baggy Wide Leg Hip Ho...   60.    4.7   \n",
      "239                   mnml Men's Baggy Every Day Denim   37.    3.6   \n",
      "\n",
      "                                          product_link  \\\n",
      "0    https://www.amazon.com/sspa/click?ie=UTF8&spc=...   \n",
      "1    https://www.amazon.com/J-Ver-Shirts-Stretch-Wr...   \n",
      "2    https://www.amazon.com/J-VER-Shirts-Cotton-Str...   \n",
      "3    https://www.amazon.com/JEMITOP-Stretch-Wrinkle...   \n",
      "4    https://www.amazon.com/Van-Heusen-Poplin-Regul...   \n",
      "..                                                 ...   \n",
      "235  https://www.amazon.com/Ylingjun-Baggy-Casual-E...   \n",
      "236  https://www.amazon.com/Hugboom-Waisted-Streetw...   \n",
      "237  https://www.amazon.com/Vintage-Stripes-Relaxed...   \n",
      "238  https://www.amazon.com/Kodaruber-Vintage-Fashi...   \n",
      "239  https://www.amazon.com/mnml-Baggy-Every-Denim-...   \n",
      "\n",
      "                image_filename category gender   style  \n",
      "0     product_1741030562_0.jpg    Shirt    Men  Formal  \n",
      "1     product_1741030568_1.jpg    Shirt    Men  Formal  \n",
      "2     product_1741030573_2.jpg    Shirt    Men  Formal  \n",
      "3     product_1741030577_3.jpg    Shirt    Men  Formal  \n",
      "4     product_1741030582_4.jpg    Shirt    Men  Formal  \n",
      "..                         ...      ...    ...     ...  \n",
      "235  product_1741031763_55.jpg    Pants    Men  Casual  \n",
      "236  product_1741031768_56.jpg    Pants    Men  Casual  \n",
      "237  product_1741031772_57.jpg    Pants    Men  Casual  \n",
      "238  product_1741031777_58.jpg    Pants    Men  Casual  \n",
      "239  product_1741031782_59.jpg    Pants    Men  Casual  \n",
      "\n",
      "[240 rows x 8 columns]\n",
      "Data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "IMAGE_FOLDER = \"product_images\"\n",
    "os.makedirs(IMAGE_FOLDER, exist_ok=True)\n",
    "\n",
    "CSV_FILE = \"amazon_data.csv\"\n",
    "MAX_PRODUCTS_PER_CATEGORY = 60\n",
    "\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        title = soup.find(\"span\", attrs={\"id\": \"productTitle\"})\n",
    "        return title.text.strip() if title else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        price = soup.find(\"span\", attrs={\"class\": \"a-price-whole\"})\n",
    "        return price.text.strip() if price else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_rating(soup):\n",
    "    try:\n",
    "        rating = soup.find(\"span\", attrs={\"class\": \"a-icon-alt\"})\n",
    "        return rating.text.split()[0] if rating else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_image(soup, product_id):\n",
    "    try:\n",
    "        img_tag = soup.find(\"img\", attrs={\"id\": \"landingImage\"})\n",
    "        img_url = img_tag[\"src\"] if img_tag else None\n",
    "        if img_url:\n",
    "            img_extension = os.path.splitext(urlparse(img_url).path)[-1]\n",
    "            img_filename = f\"{product_id}{img_extension}\"\n",
    "\n",
    "            img_path = os.path.join(IMAGE_FOLDER, img_filename)\n",
    "\n",
    "            img_data = requests.get(img_url, timeout=10).content\n",
    "            with open(img_path, \"wb\") as img_file:\n",
    "                img_file.write(img_data)\n",
    "\n",
    "            return img_filename\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def scrape_amazon_products(url, category, gender, style):\n",
    "    try:\n",
    "        webpage = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        webpage.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL {url}: {e}\")\n",
    "        return {  \n",
    "            \"title\": [], \"price\": [], \"rating\": [], \"product_link\": [], \n",
    "            \"image_filename\": [], \"category\": [], \"gender\": [], \"style\": []\n",
    "        }  \n",
    "\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    links = soup.find_all(\"a\", attrs={\"class\": \"a-link-normal s-no-outline\"})\n",
    "\n",
    "    links_list = [link.get(\"href\") for link in links if link.get(\"href\")][:MAX_PRODUCTS_PER_CATEGORY]\n",
    "\n",
    "    data = {\n",
    "        \"title\": [], \"price\": [], \"rating\": [], \"product_link\": [], \n",
    "        \"image_filename\": [], \"category\": [], \"gender\": [], \"style\": []\n",
    "    }\n",
    "\n",
    "    for index, link in enumerate(links_list):\n",
    "        if index >= MAX_PRODUCTS_PER_CATEGORY:\n",
    "            break\n",
    "\n",
    "        full_link = urljoin(\"https://www.amazon.com\", link)\n",
    "        product_id = f\"product_{int(time.time())}_{index}\"  \n",
    "\n",
    "        try:\n",
    "            new_webpage = requests.get(full_link, headers=HEADERS, timeout=10)\n",
    "            new_webpage.raise_for_status()\n",
    "            new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "            title = get_title(new_soup)\n",
    "            price = get_price(new_soup)\n",
    "            rating = get_rating(new_soup)\n",
    "            image_filename = get_image(new_soup, product_id)\n",
    "\n",
    "            if title:  \n",
    "                data[\"title\"].append(title)\n",
    "                data[\"price\"].append(price)\n",
    "                data[\"rating\"].append(rating)\n",
    "                data[\"product_link\"].append(full_link)\n",
    "                data[\"image_filename\"].append(image_filename)\n",
    "                data[\"category\"].append(category)\n",
    "                data[\"gender\"].append(gender)\n",
    "                data[\"style\"].append(style)\n",
    "\n",
    "            time.sleep(2)  \n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # print(f\"Error fetching product page {full_link}: {e}\")\n",
    "            continue  \n",
    "\n",
    "    return data \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    HEADERS = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US, en;q=0.5\",\n",
    "    }\n",
    "\n",
    "    URLS = [\n",
    "        (\"https://www.amazon.com/s?k=formal+shirts+for+men\", \"Shirt\", \"Men\", \"Formal\"),\n",
    "        (\"https://www.amazon.com/s?k=half+sleeves+shirts+for+men\", \"Shirt\", \"Men\", \"Casual\"),\n",
    "        (\"https://www.amazon.com/s?k=formal+pants+for+men\",\"Pants\",\"Men\",\"Formal\"),\n",
    "        (\"https://www.amazon.com/s?k=jeans+for+men+baggy\",\"Pants\",\"Men\",\"Casual\"),\n",
    "    ]\n",
    "\n",
    "    final_data = {\n",
    "        \"title\": [], \"price\": [], \"rating\": [], \"product_link\": [], \n",
    "        \"image_filename\": [], \"category\": [], \"gender\": [], \"style\": []\n",
    "    }\n",
    "\n",
    "    for url, category, gender, style in URLS:\n",
    "        scraped_data = scrape_amazon_products(url, category, gender, style)\n",
    "\n",
    "        for key in final_data.keys():\n",
    "            final_data[key].extend(scraped_data[key])\n",
    "\n",
    "    amazon_df = pd.DataFrame.from_dict(final_data)\n",
    "    amazon_df.replace(\"\", np.nan, inplace=True)\n",
    "    amazon_df.dropna(subset=[\"title\"], inplace=True)\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(CSV_FILE):\n",
    "            amazon_df.to_csv(CSV_FILE, mode=\"a\", header=False, index=False)\n",
    "        else:\n",
    "            amazon_df.to_csv(CSV_FILE, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving CSV: {e}\")\n",
    "\n",
    "    print(amazon_df)\n",
    "    print(\"Data saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
